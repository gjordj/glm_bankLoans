"0","##############################"
"0","# OPTIMAL CUT-OFF PROBABILITY#############################################################"
"0","##############################"
"0","#######################"
"0","# COST IN TRAINING SET#"
"0","#######################"
"0","searchgrid = seq(0.0001,0.02, 0.0001)"
"0","#result is a 99x2 matrix, the 1st col stores the cut-off p, the 2nd column stores the cost"
"0","result = cbind(searchgrid, NA)"
"0","#in the cost function, both r and pi are vectors, r=truth, pi=predicted probability"
"0","cost1 <- function(r, pi){"
"0","  weight1 = 10"
"0","  weight0 = 1"
"0","  c1 = (r==1)&(pi<pcut) #logical vector - true if actual 1 but predict 0. FP (False Positive)"
"0","  c0 = (r==0)&(pi>pcut) #logical vector - true if actual 0 but predict 1. FN (False Negative)"
"0","  return(mean(weight1*c1+weight0*c0))"
"0","}"
"0","df.glm1<-glm(default~.,family=binomial,df.train)"
"2","glm.fit: fitted probabilities numerically 0 or 1 occurred"
"0","prob <- predict(df.glm1,type=""response"")"
"0","for(i in 1:length(searchgrid))"
"0","{"
"0","  pcut <- result[i,1]"
"0","  #assign the cost to the 2nd col"
"0","  result[i,2] <- cost1(df.train$default, prob)"
"0","}"
"0","plot(result, ylab=""Cost in Training Set"")"
