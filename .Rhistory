# ERROR#
########
mean(ifelse(df.train$default != predicted.glm0.insample, 1, 0))
#################
cut_off <- 0.03#
################
prob.glm0.insample <- predict(df.glm0,type="response")
predicted.glm0.insample <- (prob.glm0.insample > cut_off)
predicted.glm0.insample <- as.numeric(predicted.glm0.insample)
###################
# CONFUSION MATRIX#
###################
table(df.train$default, predicted.glm0.insample, dnn=c("Truth","Predicted"))
########
# ERROR#
########
mean(ifelse(df.train$default != predicted.glm0.insample, 1, 0))
#################
cut_off <- 0.0009#
################
prob.glm0.insample <- predict(df.glm0,type="response")
predicted.glm0.insample <- (prob.glm0.insample > cut_off)
predicted.glm0.insample <- as.numeric(predicted.glm0.insample)
###################
# CONFUSION MATRIX#
###################
table(df.train$default, predicted.glm0.insample, dnn=c("Truth","Predicted"))
########
# ERROR#
########
mean(ifelse(df.train$default != predicted.glm0.insample, 1, 0))
############
# ROC CURVE#####################################################################################################
############
pred <- prediction(prob.glm0.insample, df.test$default)
source('~/Google Drive/DATA SCIENCE-TRADING/1_CUNEF/Prediction/2_Prediction_Code/3_GLM/Loans_GLM/Loans_GLM.R', echo=TRUE)
source('~/Google Drive/DATA SCIENCE-TRADING/1_CUNEF/Prediction/2_Prediction_Code/3_GLM/Loans_GLM/Loans_GLM.R', echo=TRUE)
# title: "Loans_GLM"
# author: "Jordi Tarroch"
# date: "02/10/2019"
##############
#LIBRARIES####
##############
library(readr)
library(skimr)# Beautiful Summarize
library(mltools)
library(cleandata)
library(shiny)
library(onehot)
library(PerformanceAnalytics) # Correlations
library(corrplot)# Correlations
library(ggcorrplot)  # Correlations
library('ROCR')
library(tidyverse)#select_at
##############
# GET DATA####
##############
path <- 'loan_filtered.csv'
raw_data <-  read_csv(path)
#####################
# DATA WRANGLING ####
#####################
dim(raw_data)
skim(raw_data) # Summarise
# CHECK DUPLICATED DATA: no duplicated data to delete.
# CHECK NA's:
raw_data<-na.omit(raw_data)
summary(raw_data$emp_length)
# ORDINAL ENCODING
levels <- c('n/a', '< 1 year', '1 year', '2 years', '3 years', '4 years', '5 years', '6 years', '7 years', '8 years', '9 years', '10+ years')
raw_data$emp_length = factor(raw_data$emp_length, order = TRUE , levels)
x <- as.data.frame(raw_data$emp_length)
raw_data$emp_length <- encode_ordinal( x, levels, none='', out.int=FALSE,
full_print=TRUE)
raw_data$emp_length <- as.numeric(unlist(raw_data$emp_length))
levels <- c('A', 'B', 'C', 'D', 'E', 'F', 'G')
raw_data$grade = factor(raw_data$grade, order = TRUE , levels)
x <- as.data.frame(raw_data$grade)
raw_data$grade <- encode_ordinal( x, levels, none='', out.int=FALSE,
full_print=TRUE)
raw_data$grade <- as.numeric(unlist(raw_data$grade))
# NOMINAL ENCODING - ONEHOT ENCODING
# https://github.com/Zelazny7/onehot
home_ownership <- as.data.frame(raw_data$home_ownership)
encoder <- onehot(home_ownership, max_levels = 15, add_NA_factors = FALSE)
home_ownership_onehot<- predict(encoder, home_ownership, stringsAsFactors=TRUE)
head(home_ownership_onehot,10)
raw_data <- cbind(raw_data, home_ownership_onehot)
purpose <- as.data.frame(raw_data$purpose)
encoder <- onehot(purpose, max_levels = 15, add_NA_factors = FALSE)
purpose_onehot<- predict(encoder, purpose, stringsAsFactors=TRUE)
head(purpose_onehot,10)
raw_data <- cbind(raw_data, purpose_onehot)
#DICOTOMIC ENCODING
default <- (raw_data$loan_status == "Default")*1
raw_data$default <- default
raw_data$term = factor(raw_data$term)
short_1_long_term_0 <- (raw_data$term == "36 months")*1
raw_data$short_1_long_term_0 <- short_1_long_term_0
#df<- subset(raw_data, select=-c(4,7,8,9))
df<- subset(raw_data, select=-c(4,7,8,9,10,12,13,16,17,18,20,21,22,23,24,25,26,28,29))
names(df)
df$int_rate <- as.double(gsub('%','',df$int_rate))/100
# Rename a column in R
names(df)
colnames(df)[colnames(df)=="raw_data$home_ownership_OWN"] <- "home_owner"
colnames(df)[colnames(df)=="raw_data$home_ownership_MORTGAGE"] <- "home_mortgage"
colnames(df)[colnames(df)=="raw_data$home_ownership_RENT"] <- "home_rent"
colnames(df)[colnames(df)=="emp_length"] <- "employment_length"
colnames(df)[colnames(df)=="raw_data$purpose_educational"] <- "purposeeducational"
colnames(df)[colnames(df)=="raw_data$purpose_small_business"] <- "purposesmallbusiness"
# skim(df)
##########################
#EXPLORATORY DATA ANALYSIS####################################################################################
##########################
#####################
# CORRELATION MATRIX#
#####################
# Correlations
corrplot(cor(df,
use = "complete.obs"),
method = "circle",type = "upper")
# Other Correlations
ggcorrplot(cor(df),
hc.order = TRUE,
type = "lower",  lab = TRUE)
res <- cor(df)
View(df)
round(res, 2)
col<- colorRampPalette(c("blue", "white", "red"))(20)
heatmap(x = res, col = col, symm = TRUE)
#Check initial correlation between variables and default based on a coefficient.
newData <- df
newData.cor = cor(newData)
# corrplot(newData.cor)
# corrplot(newData.cor, type = "upper", order = "hclust", tl.col = "black", tl.srt = 45)
newData.cor <- data.frame(newData.cor)
correlated <- c()
variable <- c()
coefficient_limit  <- c()
select_columns <-  c()
########CHANGE########
coeff <-  0.008      #
# default_column <- 26 #
default_column <- 11 #
#####################
newData.cor[default_column,1]
dim(newData.cor)[1]
for(column in 1:dim(newData.cor)[1]){
if(abs(newData.cor[default_column,column]) > coeff){
variable <-  append(variable, names(newData.cor)[column])
correlated  <-  append(correlated, newData.cor[default_column,column] )
coefficient_limit <- append(coefficient_limit,coeff)
}
}
correlated_variables <-  data.frame(variable,correlated, coefficient_limit)
# correlated_variables <-  data.frame(variable,correlated)
print(correlated_variables)
#############################################################
# RELATIONSHIPS OF NUMERIC PREDICTIVE VARIABLES WITH DEFAULT#
#############################################################
# DEFAULT VS ANNUAL_INCOME#
###########################
ggplot(data = df, aes(x = as.factor(default), y = annual_inc)) +
geom_boxplot() +
scale_y_continuous(trans = 'log10') +
ggtitle("Annual Income (log scale)") +
xlab("Default")+
ylab("Annual Income")
# DEFAULT VS INT_RATE#
######################
ggplot(data = df, aes(x = as.factor(default), y = int_rate)) +
geom_boxplot() +
ggtitle("Interest Rate") +
xlab("Default")+
ylab("Interest Rate")
# DEFAULT VS LOAN AMOUNT#
#########################
ggplot(data = df, aes(x = as.factor(default), y = loan_amnt)) +
geom_boxplot() +
ggtitle("Loan Amount") +
xlab("Default")+
ylab("Loan Amount")
#############################################
# CONTINGENCY TABLE OF CATEGORICAL VARIABLES#
#############################################
# DEFAULT VS GRADE#
###################
## two-way contingency table of categorical outcome and predictors
# grades: ('A', 'B', 'C', 'D', 'E', 'F', 'G')
contingency_table <- xtabs(~default+grade, data = df)
contingency_table_percentage <- c()
grade <- 0
for( grade in 1:dim(contingency_table)[2]){
contingency_table_percentage[grade] = contingency_table[2, grade]/contingency_table[1, grade]*100
}
# grades: ('A', 'B', 'C', 'D', 'E', 'F', 'G')
contingency_table_percentage
barplot(contingency_table_percentage,
main = "Default % vs Grades",
xlab = "Grades",
ylab = "Default %",
names.arg = c("A", "B", "C", "D", "E", "F", "G"),
col = "darkred",
horiz = FALSE)
default_total <- sum(contingency_table[2,])
# DEFAULT VS EMPLOYMENT_LENGTH#
###############################
## two-way contingency table of categorical outcome and predictors
# ('n/a', '< 1 year', '1 year', '2 years', '3 years', '4 years', '5 years', '6 years', '7 years', '8 years', '9 years', '10+ years')
contingency_table <- xtabs(~default+employment_length, data = df)
contingency_table
contingency_table_percentage <- c()
employment_length <- 0
for( employment_length in 1:dim(contingency_table)[2]){
contingency_table_percentage[employment_length] = contingency_table[2, employment_length]/contingency_table[1, employment_length]*100
}
# ('n/a', '< 1 year', '1 year', '2 years', '3 years', '4 years', '5 years', '6 years', '7 years', '8 years', '9 years', '10+ years')
contingency_table_percentage
barplot(contingency_table_percentage,
main = "Default % vs Employment Length",
xlab = "Employment Length",
ylab = "Default %",
names.arg = c('n/a', '< 1 year', '1 year', '2 years', '3 years', '4 years', '5 years', '6 years', '7 years', '8 years', '9 years', '10+ years'),
col = "darkred",
horiz = FALSE)
# DEFAULT VS HOME_MORTGAGE#
###########################
## two-way contingency table of categorical outcome and predictors
# 0,1
contingency_table <- xtabs(~default+home_mortgage, data = df)
contingency_table
contingency_table_percentage <- c()
home_mortgage <- 0
for( home_mortgage in 1:dim(contingency_table)[2]){
contingency_table_percentage[home_mortgage] = contingency_table[2, home_mortgage]/contingency_table[1, home_mortgage]*100
}
#0,1
contingency_table_percentage
barplot(contingency_table_percentage,
main = "Default % vs Home Mortgage",
xlab = "Mortgage",
ylab = "Default %",
names.arg = c('Without Mortgage', 'With Mortgage'),
col = "darkred",
horiz = FALSE)
default_total <- sum(contingency_table[2,])
# DEFAULT VS HOME_RENT#
#######################
## two-way contingency table of categorical outcome and predictors
# 0, 1
contingency_table <- xtabs(~default+home_rent, data = df)
contingency_table
contingency_table_percentage <- c()
employment_length <- 0
for( employment_length in 1:dim(contingency_table)[2]){
contingency_table_percentage[employment_length] = contingency_table[2, employment_length]/contingency_table[1, employment_length]*100
}
# ('n/a', '< 1 year', '1 year', '2 years', '3 years', '4 years', '5 years', '6 years', '7 years', '8 years', '9 years', '10+ years')
contingency_table_percentage
barplot(contingency_table_percentage,
main = "Default % vs Home Rent",
xlab = "Rent",
ylab = "Default %",
names.arg = c('Without Rent', 'With Rent'),
col = "darkred",
horiz = FALSE)
default_total <- sum(contingency_table[2,])
default_total <- sum(contingency_table[2,])
# DEFAULT VS HOME_RENT#
#######################
## two-way contingency table of categorical outcome and predictors
# 0, 1
contingency_table <- xtabs(~default+home_rent, data = df)
contingency_table
contingency_table_percentage <- c()
home_rent <- 0
for( home_rent in 1:dim(contingency_table)[2]){
contingency_table_percentage[home_rent] = contingency_table[2, home_rent]/contingency_table[1, home_rent]*100
}
# ('n/a', '< 1 year', '1 year', '2 years', '3 years', '4 years', '5 years', '6 years', '7 years', '8 years', '9 years', '10+ years')
contingency_table_percentage
default_total <- sum(contingency_table[2,])
#############
# HISTOGRAMS#
#############
ggplot(data = df) +
geom_histogram(aes(annual_inc), binwidth = 100000,)+
xlab("Anual Income")+
ggtitle("Annual Histogram")
ggplot(data = df) +
geom_histogram(aes((employment_length))) +
xlab("Employment Length")+
ggtitle("Employment Length Histogram")
ggplot(data = df) +
geom_histogram(aes(grade))
xlab("Grade")+
ggtitle("Grade Histogram")
#################################################################################################
# PREDICTION ###################################################################################
#################################################################################################
#############################
# Prepare data for the model#
#############################
# Scaling numeric variables of values not between 0-1.
scale <- function(x) {
minD <- mean(x)
maxD <- sd(x)
res <- (x - minD) / (maxD)
return(res)
}
df$annual_inc <- scale(df$annual_inc)
df$int_rate   <- scale(df$int_rate)
df$employment_length <- scale(df$employment_length)
# Logistic regression is a method for fitting a regression curve, y = f(x), when y is a categorical variable.
# The typical use of this model is predicting y given a set of predictors x. The predictors can be continuous,
# categorical or a mix of both.
# In order to create our model we are going to use the previous predictive variables studied.
vars <- c("purposesmallbusiness","purposeeducational","short_1_long_term_0")
df <- df %>%  select_at(vars(-vars))
View(df)
##################
# MODEL (BINOMIAL) #################################################################################
##################
# We indicate that we use a logistic regression with the family binomial.
mod01 = glm(default~ . ,family="binomial",data= df)
summary(mod01)
############
# ROC CURVE#####################################################################################################
############
pred <- prediction(prob.glm0.insample, df.test$default)
#########################################
# PREDICTION IN-SAMPLE AND OUT OF SAMPLE#######################################################
#########################################
#####################################
# IN SAMPLE TRYING DIFFERENT CUT_OFFS####################################################
#####################################
#######################
cut_off <- 0.001300000#
#######################
prob.glm0.insample <- predict(df.glm0,type="response")
###########################################################
# MATRIX CONFUSION AND ROC CURVE(AREA UNDER THE CURVE(AUC))############################################
###########################################################
#TRAINING AND TESTING DATA
set.seed(1234)
n=nrow(df)
id_train <- sample(1:n , 0.90*n)
df.train = df[id_train,]
df.test = df[-id_train,]
nrow(df.train)
ncol(df.train)
colnames(df.train)
# LOGISTIC REGRESSION TRAIN MODEL
df.glm0<-glm(default~.,family=binomial,df.train);
summary(df.glm0)
# # CROSS VALIDATION AND PREDICTION WITH LOGISTIC REGRESSION
# df.glm1<-glm(default~int_rate+annual_inc,family=binomial,df.train);
# AIC(df.glm0)
# AIC(df.glm1)
# BIC(df.glm0)
# BIC(df.glm1)
######################################################
# LOGISTIC REGRESSION: CLASSIFICATION DECISION MAKING#
######################################################
ggplot(data = as.data.frame(predict(df.glm0))) +
geom_histogram(aes(x = predict(df.glm0)),
binwidth = .1) +
xlim(-10,0) + xlab("Prediction Values")
ggplot(data = as.data.frame(predict(df.glm0, type="response"))) +
geom_histogram(aes(x = predict(df.glm0, type="response")),
binwidth = .0001) +
xlim(0,0.01) + xlab("Prediction Values")
# table(predict(df.glm0,type="response") > 0.005)
# table(predict(df.glm0,type="response") > 0.008)
# table(predict(df.glm0,type="response") > 0.009)
# table(predict(df.glm0,type="response") > 0.01)
# table(predict(df.glm0,type="response") > 0.02)
# table(predict(df.glm0,type="response") > 0.03)
#########################################
# PREDICTION IN-SAMPLE AND OUT OF SAMPLE#######################################################
#########################################
#####################################
# IN SAMPLE TRYING DIFFERENT CUT_OFFS####################################################
#####################################
#######################
cut_off <- 0.001300000#
#######################
prob.glm0.insample <- predict(df.glm0,type="response")
predicted.glm0.insample <- (prob.glm0.insample > cut_off)
predicted.glm0.insample <- as.numeric(predicted.glm0.insample)
###################
# CONFUSION MATRIX#
###################
table(df.train$default, predicted.glm0.insample, dnn=c("Truth","Predicted"))
########
# ERROR#
########
mean(ifelse(df.train$default != predicted.glm0.insample, 1, 0))
#################
cut_off <- 0.03#
################
prob.glm0.insample <- predict(df.glm0,type="response")
predicted.glm0.insample <- (prob.glm0.insample > cut_off)
predicted.glm0.insample <- as.numeric(predicted.glm0.insample)
###################
# CONFUSION MATRIX#
###################
table(df.train$default, predicted.glm0.insample, dnn=c("Truth","Predicted"))
########
# ERROR#
########
mean(ifelse(df.train$default != predicted.glm0.insample, 1, 0))
#################
cut_off <- 0.0009#
################
prob.glm0.insample <- predict(df.glm0,type="response")
predicted.glm0.insample <- (prob.glm0.insample > cut_off)
predicted.glm0.insample <- as.numeric(predicted.glm0.insample)
###################
# CONFUSION MATRIX#
###################
table(df.train$default, predicted.glm0.insample, dnn=c("Truth","Predicted"))
########
# ERROR#
########
mean(ifelse(df.train$default != predicted.glm0.insample, 1, 0))
############
# ROC CURVE#####################################################################################################
############
pred <- prediction(prob.glm0.insample, df.test$default)
############
# ROC CURVE#####################################################################################################
############
pred <- prediction(prob.glm0.insample, df.test$default)
#########################################
# PREDICTION IN-SAMPLE AND OUT OF SAMPLE#######################################################
#########################################
#####################################
# IN SAMPLE TRYING DIFFERENT CUT_OFFS####################################################
#####################################
#######################
cut_off <- 0.001300000#
#######################
prob.glm0.insample <- predict(df.glm0,type="response")
predicted.glm0.insample <- (prob.glm0.insample > cut_off)
predicted.glm0.insample <- as.numeric(predicted.glm0.insample)
###################
# CONFUSION MATRIX#
###################
table(df.train$default, predicted.glm0.insample, dnn=c("Truth","Predicted"))
########
# ERROR#
########
mean(ifelse(df.train$default != predicted.glm0.insample, 1, 0))
#################
cut_off <- 0.03#
################
prob.glm0.insample <- predict(df.glm0,type="response")
predicted.glm0.insample <- (prob.glm0.insample > cut_off)
predicted.glm0.insample <- as.numeric(predicted.glm0.insample)
###################
# CONFUSION MATRIX#
###################
table(df.train$default, predicted.glm0.insample, dnn=c("Truth","Predicted"))
########
# ERROR#
########
mean(ifelse(df.train$default != predicted.glm0.insample, 1, 0))
#################
cut_off <- 0.0009#
################
prob.glm0.insample <- predict(df.glm0,type="response")
predicted.glm0.insample <- (prob.glm0.insample > cut_off)
predicted.glm0.insample <- as.numeric(predicted.glm0.insample)
###################
# CONFUSION MATRIX#
###################
table(df.train$default, predicted.glm0.insample, dnn=c("Truth","Predicted"))
########
# ERROR#
########
mean(ifelse(df.train$default != predicted.glm0.insample, 1, 0))
############
# ROC CURVE#####################################################################################################
############
pred <- prediction(prob.glm0.insample, df.test$default)
###########################################################
# MATRIX CONFUSION AND ROC CURVE(AREA UNDER THE CURVE(AUC))############################################
###########################################################
#TRAINING AND TESTING DATA
set.seed(1234)
n=nrow(df)
id_train <- sample(1:n , 0.90*n)
df.train = df[id_train,]
df.test = df[-id_train,]
nrow(df.train)
ncol(df.train)
colnames(df.train)
# LOGISTIC REGRESSION TRAIN MODEL
df.glm0<-glm(default~.,family=binomial,df.train);
summary(df.glm0)
# # CROSS VALIDATION AND PREDICTION WITH LOGISTIC REGRESSION
# df.glm1<-glm(default~int_rate+annual_inc,family=binomial,df.train);
# AIC(df.glm0)
# AIC(df.glm1)
# BIC(df.glm0)
# BIC(df.glm1)
############
# ROC CURVE#####################################################################################################
############
pred <- prediction(prob.glm0.insample, df.test$default)
